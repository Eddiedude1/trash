{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Lab 8.01 | Topic Modeling & Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1:** Define supervised learning and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** no target with unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2:** Give an example of a supervised learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** try to figure out score to a knicks game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3:** Give an example of an unsupervised learning problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** topics within a google search throughout the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4:** Imagine you're in a non-technical interview with a non-technical recruiter. How would you define supervised learning and unsupervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Say we are classifying triangles, squares, and diamonds. Unsupervised learning is grouping these shapes without ever seeing them before. Supervised learning is where we know what a triangle, square and diamond is and then we can classify the shapes, based on number of verticies, and angle size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = sklearn.datasets.fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(newsgroups_train.data, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[0,\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lerxst',\n",
       " 'wam',\n",
       " 'umd',\n",
       " 'edu',\n",
       " 'thing',\n",
       " 'subject',\n",
       " 'car',\n",
       " 'nntp',\n",
       " 'post',\n",
       " 'host',\n",
       " 'rac3',\n",
       " 'wam',\n",
       " 'umd',\n",
       " 'edu',\n",
       " 'organ',\n",
       " 'univers',\n",
       " 'maryland',\n",
       " 'colleg',\n",
       " 'park',\n",
       " 'line',\n",
       " '15',\n",
       " 'wonder',\n",
       " 'anyon',\n",
       " 'could',\n",
       " 'enlighten',\n",
       " 'car',\n",
       " 'saw',\n",
       " 'day',\n",
       " '2',\n",
       " 'door',\n",
       " 'sport',\n",
       " 'car',\n",
       " 'look',\n",
       " 'late',\n",
       " '60',\n",
       " 'earli',\n",
       " '70',\n",
       " 'call',\n",
       " 'bricklin',\n",
       " 'door',\n",
       " 'realli',\n",
       " 'small',\n",
       " 'addit',\n",
       " 'front',\n",
       " 'bumper',\n",
       " 'separ',\n",
       " 'rest',\n",
       " 'bodi',\n",
       " 'know',\n",
       " 'anyon',\n",
       " 'tellm',\n",
       " 'model',\n",
       " 'name',\n",
       " 'engin',\n",
       " 'spec',\n",
       " 'year',\n",
       " 'product',\n",
       " 'car',\n",
       " 'made',\n",
       " 'histori',\n",
       " 'whatev',\n",
       " 'info',\n",
       " 'funki',\n",
       " 'look',\n",
       " 'car',\n",
       " 'pleas',\n",
       " 'e',\n",
       " 'mail',\n",
       " 'thank',\n",
       " 'il',\n",
       " 'brought',\n",
       " 'neighborhood',\n",
       " 'lerxst']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_process(train.loc[0,\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5:** Build an LDA model on the training data with 20 topics. Summarize any findings. Be sure to preprocess your data accordingly!\n",
    "- Note that pre-processing your data will likely take ten or so minutes; if you use a loop to pre-process your data, you should consider adding some `print` statement that will let you know every 1,000 entries that you are indeed making progress.\n",
    "- Fitting the LDA model won't take as long, but will still take longer given the larger size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "        1. Tokenizes and removes punctuation\n",
    "        2. Removes stopwords\n",
    "        3. Stems\n",
    "        4. Returns a list of the cleaned text\n",
    "    '''\n",
    "    if pd.isnull(text):\n",
    "        return []\n",
    "    # tokenizing and removing punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text_processed=tokenizer.tokenize(text)\n",
    "    \n",
    "    # removing any stopwords\n",
    "    text_processed = [word.lower() for word in text_processed if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # steming\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
    "    \n",
    "    try:\n",
    "        text_processed.remove('b')\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "    return text_processed ## <-- one small tweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in range(500):\n",
    "    texts.append(text_process(train.iloc[i,:].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel(corpus, \n",
    "                                    id2word = dictionary, \n",
    "                                    num_topics = 20, \n",
    "                                    passes = 5, \n",
    "                                    minimum_probability=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00342079,  0.00339651,  0.0034052 , ...,  0.00016941,\n",
       "         0.00016941,  0.00016941],\n",
       "       [ 0.00130739,  0.00165799,  0.00125329, ...,  0.00125329,\n",
       "         0.00125329,  0.00125329],\n",
       "       [ 0.00135328,  0.00135685,  0.00135275, ...,  0.00135275,\n",
       "         0.00135275,  0.00135275],\n",
       "       ..., \n",
       "       [ 0.00290747,  0.02225376,  0.00014413, ...,  0.00014413,\n",
       "         0.00014413,  0.00014413],\n",
       "       [ 0.00160638,  0.00218157,  0.00175404, ...,  0.00125447,\n",
       "         0.00125447,  0.00125447],\n",
       "       [ 0.001653  ,  0.00315747,  0.00152491, ...,  0.00123006,\n",
       "         0.00126849,  0.00122341]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.get_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6:** Let's walk through using a cool visualization library, called [Bokeh](https://bokeh.pydata.org). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1:** Run the following cell. This will convert our LDA results into an array of size `number_of_documents` $\\times$ `number_of_topics`. Remember that each document is a combination of topics; this code shows us the distribution of topics for a given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_x_topic = np.array([[y for (x,y) in ldamodel[corpus[i]]] for i in range(len(corpus))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2:** Run the following cell. \n",
    "\n",
    "Remember that very topic is defined by all of the words in our corpus. For example, the topic magic, might be defined by the words {spell, wand, wizard}. The topic magic, then, is defined in three dimensions.\n",
    "\n",
    "If we have a corpus of more than three words (which is going to basically be 100% of the time), then it will be very difficult to visualize our topics.\n",
    "- In using `pyLDAvis.gensim.prepare()`, the function \"projected\" our data from high dimensions into only two dimensions using something called **principal component analysis**. We'll learn about PCA later this week!\n",
    "- There's another commonly used method of projecting data into lower dimensions, called [**t-Stochastic Neighbor Embedding**](https://lvdmaaten.github.io/tsne/). We won't go into the details here, but you're welcome to learn more about it if you'd like. We're just using it so that it makes visualizations easier.\n",
    "\n",
    "Run the following cell. It'll implement t-SNE for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=42, perplexity=30)        # Instantiates Model\n",
    "tsne_embedding = tsne.fit_transform(doc_x_topic)   # Fits Model/Transforms the Data\n",
    "tsne_embedding = pd.DataFrame(tsne_embedding, columns=['x','y']) # Creates Pandas Dataframe of TSNE results.\n",
    "tsne_embedding['hue'] = doc_x_topic.argmax(axis=1) # Creates \"hue\" based on likeliest topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of any metrics telling us whether we have a \"good\" or \"bad\" model, this will help us to better visualize the performance of our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3:** Run the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool, CustomJS, ColumnDataSource, Slider\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x = tsne_embedding.x,\n",
    "            y = tsne_embedding.y,\n",
    "            colors = [all_palettes['Category20'][20][i] for i in tsne_embedding.hue],\n",
    "            topic = [i for i in tsne_embedding.hue],\n",
    "            alpha = [0.7] * tsne_embedding.shape[0],\n",
    "            size = [5] * tsne_embedding.shape[0]\n",
    "        )\n",
    "    )\n",
    "\n",
    "hover_tsne = HoverTool(names=[\"train\"], tooltips=\"\"\"\n",
    "    <div style=\"margin: 10\">\n",
    "        <div style=\"margin: 0 auto; width:300px;\">\n",
    "            <span style=\"font-size: 12px; font-weight: bold;\">Topic:</span>\n",
    "            <span style=\"font-size: 12px\">@topic</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "tools_tsne = [hover_tsne, 'pan', 'wheel_zoom', 'reset']\n",
    "plot_tsne = figure(plot_width=700, plot_height=700, tools=tools_tsne, title='Newsgroups')\n",
    "plot_tsne.circle('x', 'y', size='size', fill_color='colors', \n",
    "                 alpha='alpha', line_alpha=0, line_width=0.01, source=source, name=\"train\")\n",
    "\n",
    "callback = CustomJS(args=dict(source=source), code=\"\"\"\n",
    "    var data = source.data;\n",
    "    var f = cb_obj.value\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    colors = data['colors']\n",
    "    alpha = data['alpha']\n",
    "    size = data['size']\n",
    "    for (i = 0; i < x.length; i++) {\n",
    "        alpha[i] = 0.7\n",
    "        size[i] = 5\n",
    "    }\n",
    "    source.trigger('change');\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show(plot_tsne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bokeh is a great library for interactive visualizations! It offers us a lot of flexibility to generate visualizations for ourselves or for stakeholders. While knowing Javascript is helpful, the [Bokeh gallery](https://bokeh.pydata.org/en/latest/docs/gallery.html) and the [Bokeh reference guide](https://bokeh.pydata.org/en/latest/docs/reference.html) are very helpful to those of us who don't know JavaScript.\n",
    "\n",
    "It also works really well with other packages, including NetworkX!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 7:** Go through the next cell and comment each line. What does each line appear to be doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "from bokeh.io import show, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models.graphs import from_networkx\n",
    "\n",
    "G=nx.karate_club_graph()\n",
    "\n",
    "plot = figure(title=\"Networkx Integration Demonstration\", x_range=(-1.1,1.1), y_range=(-1.1,1.1),\n",
    "              tools=\"\", toolbar_location=None)\n",
    "\n",
    "graph = from_networkx(G, nx.spring_layout, scale=2, center=(0,0))\n",
    "plot.renderers.append(graph)\n",
    "\n",
    "output_file(\"networkx_graph.html\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 8:** Run the next cell. What are the benefits to having a visualization like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "from bokeh.io import show, output_file\n",
    "from bokeh.models import Plot, Range1d, MultiLine, Circle, HoverTool, TapTool, BoxSelectTool\n",
    "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges, EdgesAndLinkedNodes\n",
    "from bokeh.palettes import Spectral4\n",
    "\n",
    "G=nx.karate_club_graph()\n",
    "\n",
    "plot = Plot(plot_width=400, plot_height=400,\n",
    "            x_range=Range1d(-1.1,1.1), y_range=Range1d(-1.1,1.1))\n",
    "plot.title.text = \"Graph Interaction Demonstration\"\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=None), TapTool(), BoxSelectTool())\n",
    "\n",
    "graph_renderer = from_networkx(G, nx.circular_layout, scale=1, center=(0,0))\n",
    "\n",
    "graph_renderer.node_renderer.glyph = Circle(size=15, fill_color=Spectral4[0])\n",
    "graph_renderer.node_renderer.selection_glyph = Circle(size=15, fill_color=Spectral4[2])\n",
    "graph_renderer.node_renderer.hover_glyph = Circle(size=15, fill_color=Spectral4[1])\n",
    "\n",
    "graph_renderer.edge_renderer.glyph = MultiLine(line_color=\"#CCCCCC\", line_alpha=0.8, line_width=5)\n",
    "graph_renderer.edge_renderer.selection_glyph = MultiLine(line_color=Spectral4[2], line_width=5)\n",
    "graph_renderer.edge_renderer.hover_glyph = MultiLine(line_color=Spectral4[1], line_width=5)\n",
    "\n",
    "graph_renderer.selection_policy = NodesAndLinkedEdges()\n",
    "graph_renderer.inspection_policy = EdgesAndLinkedNodes()\n",
    "\n",
    "plot.renderers.append(graph_renderer)\n",
    "\n",
    "output_file(\"interactive_graphs.html\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 9:** Referring to the previous cell, what might be a case when the previous visualization is not helpful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 10:** Create at least two more interactive graphs in Bokeh. They can be networks, topic models, or something else... perhaps related to your upcoming project??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
